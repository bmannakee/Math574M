\documentclass{article}
\usepackage[top=2in, bottom=1in, left=1in, right=1in]{geometry}
\usepackage{fancyhdr}
\usepackage{amsmath}
\pagestyle{fancyplain}
\begin{document}
\lhead{Math 574M\\ Homework 1}
\rhead{Brian Mannakee\\ \today}


\SweaveOpts{concordance=TRUE}


\begin{enumerate}
  \item X is a continuous random variable with F(X),f(x)
    \begin{enumerate}
      \item \begin{eqnarray*}E(X-a)^2 &=& E[X^2 - 2aX + a^2]\\ &=& E(X^2) -2aE(X) + a^2\end{eqnarray*}
          To minimize, take the first derivative with respect a and set equal to zero. Then take the second derivative with respect to a and check that the sign is positive.
            \begin{eqnarray*}\frac{d}{da}[E(X^2) - 2aE(X) + a^2] &=& 0 \\ 2E(X) + 2a &=& 0 \\ a &=& E(X)\\
            \frac{d}{da}[2E(X) + 2a] &=& 2 \end{eqnarray*}
            Therefore $a=E(X)$ is a minimum
      \item Set the derivative equal to zero
            \begin{eqnarray*}E(|X-a|) &=& \int|X-a|f(x)dx \\
                                      &=& \int_{-\infty}^a -(X-a)f(x)dx + \int_a^\infty (X-a)f(x)dx \\
                \frac{d}{da}E(|X-a|)  &=& \frac{d}{da}[\int_{-\infty}^a -(X-a)f(x)dx + \int_a^\infty (X-a)f(x)dx] \\
                                    0 &=& \int_{-\infty}^a f(x)dx - \int_a^\infty f(x)dx \\
              \int_{-\infty}^a f(x)dx &=& \int_a^\infty f(x)dx \\
                                      \end{eqnarray*}
            This equality only holds when a is the median of the distribution. In addition $d^2/da^2 = 2f(a) > 0$ so the median is the minimu,.
    \end{enumerate}
  \item If $X_1,\dots,X_n$ are i.i.d Bernoulli(p) then $Y = \sum X_i \sim $ Binomial(n,p). If $p \sim beta(\alpha,\beta)$ then their joint pdf is
    \begin{eqnarray*}
        f(y,p) &=& \left[{n \choose y}p^y(1-p)^{n-y}\right] \left[\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(
        beta)}p^{\alpha-1}(1-p)^{\beta-1}\right]\\
               &=& {n \choose y}\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(
        beta)}p^{y+\alpha-1}(1-p)^{n-y+\beta-1}
    \end{eqnarray*}
    We get the marginal of y by integrating out p from the joint distribution.
    \begin{eqnarray*}
      f(y) &=& \int_0^1{n \choose y}\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(
        beta)}p^{y+\alpha-1}(1-p)^{n-y+\beta-1}dp \\
           &=&{n \choose y}\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}\int_0^1 p^{y+\alpha-1}(1-p)^{n-y+\beta-1}dp \\
           &=&{n \choose y}\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}\frac{\Gamma(y+\alpha)\Gamma(n-y+\beta)}{\Gamma(n + \alpha + \beta)}  \text{By definition of the Beta function}
    \end{eqnarray*}
    The posterior $f(p|y)$ is given by the ratio of the joint and the marginal $\frac{f(y,p)}{f(y)}$
    \begin{eqnarray*}
      f(p|y)=\frac{\Gamma(n + \alpha + \beta)}{\Gamma(y+\alpha)\Gamma(n-y+\beta)}p^{y+\alpha-1}(1-p)^{n-y+\beta-1} \sim beta(y+\alpha,n-y+\beta)
    \end{eqnarray*}
      \begin{enumerate}
        \item The posterior mean is the mean of $beta(y+\alpha,n-y+\beta)$ which is
        $$\hat{p}=\frac{y+\alpha}{\alpha + \beta + n}=\frac{\sum_{i=1}^{n}X_i+\alpha}{\alpha + \beta + n}//$$
        \item Find 
      \end{enumerate}
\end{enumerate}















\end{document}







